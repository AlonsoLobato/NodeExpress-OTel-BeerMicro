## Microservice architecture observed with Otel
Distributed architecture consisting on three microservices, `inventory-service` (running on port 3000), `bar-service` (running on port 3001), and `brewery-service` (running on port 3002) which communicate with each other using RabbitMQ. 

The traces generated by the interaction between the services is observed using OpenTelemetry (OTel) SDK and autoinstrumentation, and can be visualized via the Jaeger UI.

### Statement of intention
This is a personal side project made with the intention of learning OpenTelemetry observability solutions for distributed systems.

### Brief explanation of the architecture pipeline
`brewery-service` fetches a new random beer item from an external API, and sends it to `inventory-service` for storage in database. 

`bar-service` communicate with `inventory-service` to fetch full list of available beers (bar-menu) in the database. 

The communication from `brewery-service` and `bar-service` with `inventory-service` and viceversa, is made using RabbitMQ message queues.

### Project structure
NodeExpress-OTel-BeerMicro
- bar-service
  - routes
    - `bar-api.js`
  - `index.js`
  - `package.json`
- brewery-service
  - routes
    - `brewery-api.js`
  - `index.js`
  - `package.json`
- inventory-service
  - Models
    - DataAccess
      - `InventoryRepository.js`
    - `BeerModel.js`
  - `index.js`
  - `package.json`
- `package.json`
- `tracer.js`      

### Prerequisites
Before running the application, make sure you have the following dependencies installed:

1. NodeJS (v18.13.0)
```bash
# Verify NodeJS version
node -v
```
2. NPM (v8.19.3)
```bash
# Verify NPM version
npm -v
```

3. Docker desktop - [install from here](https://docs.docker.com/desktop/install/mac-install/)

4. RabbitMQ messages broker (Docker image: rabbitmq:3-management):
```bash
docker run --rm -p 5672:5672 -p 15672:15672 -d --name rabbit rabbitmq:3-management`. 
```

5. Jaeger tracing platform (Docker image: jaegertracing/all-in-one:1.53):
```bash
  docker run --rm --name jaeger \
    -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \
    -p 6831:6831/udp \
    -p 6832:6832/udp \
    -p 5778:5778 \
    -p 16686:16686 \
    -p 4317:4317 \
    -p 4318:4318 \
    -p 14250:14250 \
    -p 14268:14268 \
    -p 14269:14269 \
    -p 9411:9411 \
    jaegertracing/all-in-one:1.53
  ```

6. MongoDB database instance (or MongoDB Atlas cluster). Create a `.env` file and add a `MONGODB_URI` variable that references your MongoDB database connection string, including your databse username and password.

### Installation and usage
1. Clone the repository (`git clone `)
2. From the root directory execute `npm install`, so the OTel dependencies are installed.  
3. Open three separate terminal sessions and `cd` into each service directory (`bar`, `brewery` and `inventory`).
4. Install the dependencies in each service with `npm install`.
5. Run each service with `npm run dev` to run in dev mode (the app uses `nodemon`) or `npm start` to run in production mode.  
6. Using an API client of your choice (e.g. Postman) send a `GET` API call to `http://localhost:3001/barMenu` to fetch the whole list of beers stored in the database menu or a `GET` API call to `http://localhost:3002/newBeer` to create a new random beer and add it to the database. 

### Observability
The `tracer.js` file in the root directory contains the OTel SDK and autoinstrumentation to export telemetry signals (traces) from the application directly into the Jaeger backend.

The app is instrumented to collect traces from the amqplib (RabbitMQ library), http, express and mongoose modules. Notice how in each service's file (`bar`, `brewery` and `inventory`) the tracing function gets required and invoked before any other code runs.

The generated traces can be viewed in the Jaeger UI on `http://localhost:16686/` 

### Future work
#### Implement OTel collectors
This repository showcases observability in distributed applications by using the OpenTelemetry (OTel) SDK to instrument the code, and sending the generated telemetry signals (in this case traces) directly to a Jaeger backend.

For an initial approach into observability with OTel, sending data directly to a backend is an easy way to quickly gaining insights. Also, in a development or small-scale environment, this simple method offers decent overall results.

However, it's important to note that this architecture, while straightforward (OTel SDK sending traces to a backend), introduces a tight coupling between the application code and the observability backend. Therefore, it is generally advisable to incorporate a collector alongside your service. This way we can alleviate the work the app does to gather and export telemetry data, reducing overhead and separating concerns, and passing this job to the collector, so the app can focus on the business logic side. 

The collector provides a vendor-neutral mechanism for collecting, processing, and exporting the telemetry data generated by your system. Configuration options for the collector include defining one or more pipelines, each comprising receivers (to receive data), optional processors (to process data from receivers), and exporters (to send processed data outside the collector).

A logical progression in the observability architecture in this repository, should involve introducing an OTel Collector, first used as a Gateway, and in a second stage adding it as a Collector-agent. 
